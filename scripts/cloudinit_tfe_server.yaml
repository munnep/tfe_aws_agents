#cloud-config
write_files:
  - content: |
      {
          "DaemonAuthenticationType":          "password",
          "DaemonAuthenticationPassword":      "${tfe_password}",
          "TlsBootstrapType":                  "server-path",
          "TlsBootstrapHostname":              "${dns_hostname}.${dns_zonename}",
          "TlsBootstrapCert":                  "/tmp/fullchain_pem",
          "TlsBootstrapKey":                   "/tmp/private_key_pem",
          "BypassPreflightChecks":             true,
          "ImportSettingsFrom":                "/tmp/tfe_settings.json",
          "LicenseFileLocation":               "/tmp/${filename_license}",
          "LicenseBootstrapAirgapPackagePath": "/tmp/${filename_airgap}"
      }
    permissions: '0640'
    path: /etc/replicated.conf
  - content: |
      {
         "aws_instance_profile": {
              "value": "1"
          },
          "enc_password": {
              "value": "${tfe_password}"
          },
          "hairpin_addressing": {
              "value": "1"
          },
          "hostname": {
              "value": "${dns_hostname}.${dns_zonename}"
          },
          "pg_dbname": {
              "value": "${pg_dbname}"
          },
          "pg_netloc": {
              "value": "${pg_address}"
          },
          "pg_password": {
              "value": "${rds_password}"
          },
          "pg_user": {
              "value": "postgres"
          },
          "placement": {
              "value": "placement_s3"
          },
          "production_type": {
              "value": "external"
          },
          "s3_bucket": {
              "value": "${tfe_bucket}"
          },
          "s3_endpoint": {},
          "s3_region": {
              "value": "${region}"
          }
      }
    permissions: '0640'
    path: /tmp/tfe_settings.json 
  - content: |
      #!/usr/bin/env bash
      # installation script for software
      # first is Alvaro
      cat >> /home/ubuntu/.ssh/authorized_keys <<EOF
      ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDBzMaSE9ORQsJoIi+UrMQ+U8WFSpiYFXIKSvqFWbqyhpEM6MSoidX09CuvYIVPMtTeZZj/ZO+o+nL0TffIDNzkGgalhdlw5RL9OgJXgmUNWjW4VwIoR96D7TcP6EUyXkD0wxSgjryJSn4aONR3tIIYvHdM9YjRrivLlS/N7WzIRM6xvWJ8UK7fVYdD3V6FMp4+a33Uc+Ezk8XPWCvDt5vXluFPiKa8RlU7XXqPqI2bR89VJ5cpCnZorVtjVVlvgtOFdY/5hT7qqX1hxQyARkSLcnJiVylL3H3arDlnT/6nO71WY2/ZfyVUbQqcTC12UpFSJRH7JRCgf0stTdfzugCsq61XCMkZBfZ2OTBWeO8Qm2yDW7d4NwzKj31xKqDxT3sr7Gz6qiJO0XhaEjgBSAFB41hVDaNR8Fa6Ir1DObVQ+QsHOv4m2xhh8XxLaZZh30KWZNFAxVmeXoec0paDuj53UTM/ddhbKQr+8vPkbdlR4p5hxSSoVH+SBNLmGY4+K+0= kikitux@kikitux-C02ZR1GLLVDM
      EOF
      
      # wait until archive is available. Wait until there is internet before continue
      until ping -c1 archive.ubuntu.com &>/dev/null; do
       echo "waiting for networking to initialise"
       sleep 3 
      done 
      
      # install monitoring tools
      apt-get update
      apt-get install -y ctop net-tools sysstat jq
      
      # Set swappiness
      if test -f /sys/kernel/mm/transparent_hugepage/enabled; then
        echo never > /sys/kernel/mm/transparent_hugepage/enabled
      fi
      
      if test -f /sys/kernel/mm/transparent_hugepage/defrag; then
        echo never > /sys/kernel/mm/transparent_hugepage/defrag
      fi
      
      # heavy swap vm.swappiness=80
      # no swap vm.swappiness=1
      sysctl vm.swappiness=1
      sysctl vm.min_free_kbytes=67584
      sysctl vm.drop_caches=1
      # make it permanent over server reboots
      echo vm.swappiness=1 >> /etc/sysctl.conf
      echo vm.min_free_kbytes=67584 >> /etc/sysctl.conf
      
      
      SWAP=/dev/$(lsblk|grep nvme | grep -v nvme0n1 |sort -k 4 | awk '{print $1}'| awk '(NR==1)')
      DOCKER=/dev/$(lsblk|grep nvme | grep -v nvme0n1 |sort -k 4 | awk '{print $1}'| awk '(NR==2)')
      
      
      echo $SWAP
      echo $DOCKER
      echo $TFE
      
      # swap
      # if SWAP exists
      # we format if no format
      if [ -b $SWAP ]; then
      	blkid $SWAP
      	if [ $? -ne 0 ]; then
      		mkswap $SWAP
      	fi
      fi
      
      # if SWAP not in fstab
      # we add it
      grep "swap" /etc/fstab
      if [ $? -ne 0 ]; then
        SWAP_UUID=`blkid $SWAP| awk '{print $2}'`
      	echo "$SWAP_UUID swap swap defaults 0 0" | tee -a /etc/fstab
      	swapon -a
      fi
      
      # docker
      # if DOCKER exists
      # we format if no format
      if [ -b $DOCKER ]; then
      	blkid $DOCKER
      	if [ $? -ne 0 ]; then
      		mkfs.xfs $DOCKER
      	fi
      fi
      
      # if DOCKER not in fstab
      # we add it
      grep "/var/lib/docker" /etc/fstab
      if [ $? -ne 0 ]; then
        DOCKER_UUID=`blkid $DOCKER| awk '{print $2}'`
      	echo "$DOCKER_UUID /var/lib/docker xfs defaults 0 0" | tee -a /etc/fstab
      	mkdir -p /var/lib/docker
      	mount -a
      fi
      
      # Netdata will be listening on port 19999
      curl -sL https://raw.githubusercontent.com/automodule/bash/main/install_netdata.sh | bash
      
      # install requirements for tfe
      curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
      echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
      apt-get update
      apt-get -y install docker-ce docker-ce-cli containerd.io docker-compose-plugin
    permissions: '0750'
    path: /tmp/install_software.sh 
  - content: |
      #!/usr/bin/env bash
      # only really needed when not using valid certificates
      # echo -n | openssl s_client -connect ${dns_hostname}.${dns_zonename}:443 | openssl x509 > tfe_certificate.crt
      # sudo cp tfe_certificate.crt /usr/local/share/ca-certificates/
      # sudo update-ca-certificates
      # We have to wait for TFE be fully functioning before we can continue
      while true; do
          if curl -I "https://${dns_hostname}.${dns_zonename}/admin" 2>&1 | grep -w "200\|301" ; 
          then
              echo "TFE is up and running"
              echo "Will continue in 1 minutes with the final steps"
              sleep 60
              break
          else
              echo "TFE is not available yet. Please wait..."
              sleep 60
          fi
      done
      # get the admin token you can user to create the first user
      ADMIN_TOKEN=`sudo /usr/local/bin/replicated admin --tty=0 retrieve-iact | tr -d '\r'`
      # echo ADMIN_TOKEN $ADMIN_TOKEN
      # Create the first user called admin and get the token
      TOKEN=`curl --header "Content-Type: application/json" --request POST --data '{"username": "admin", "email": "${certificate_email}", "password": "${tfe_password}"}' \ --url https://${dns_hostname}.${dns_zonename}/admin/initial-admin-user?token=$ADMIN_TOKEN | jq '.token' | tr -d '"'`
      # echo TOKEN $TOKEN
      # create the organization called test
      curl \
        --header "Authorization: Bearer $TOKEN" \
        --header "Content-Type: application/vnd.api+json" \
        --request POST \
        --data '{"data": { "type": "organizations", "attributes": {"name": "test", "email": "${certificate_email}"}}}' \
        https://${dns_hostname}.${dns_zonename}/api/v2/organizations
      # Create an agent pool
      export AGENT_POOL=`curl --header "Authorization: Bearer $TOKEN" --header "Content-Type: application/vnd.api+json" --request POST --data '{"data": {"type": "agent-pools", "attributes": { "name": "test-pool", "organization-scoped": true}}}' https://${dns_hostname}.${dns_zonename}/api/v2/organizations/test/agent-pools | jq '.data.relationships."authentication-tokens".links.related' | tr -d '"'`
      # Create a workspace
      export AGENT_POOL_ID=`curl --header "Authorization: Bearer $TOKEN" --header "Content-Type: application/vnd.api+json" --request GET https://patrick-tfe6.bg.hashicorp-success.com/api/v2/organizations/test/agent-pools | jq '.data[0].id' | tr -d '"'`
      curl --header "Authorization: Bearer $TOKEN" --header "Content-Type: application/vnd.api+json" --request POST --data '{"data": {"attributes": {"name":"test-agent","execution-mode": "agent", "agent-pool-id": "'$AGENT_POOL_ID'","resource-count": 0,"updated-at": "2017-11-29T19:18:09.976Z"}},"type": "workspaces"}' https://patrick-tfe6.bg.hashicorp-success.com/api/v2/organizations/test/workspaces
      # Create an agent token
      export AGENT_TOKEN=`curl --header "Authorization: Bearer $TOKEN" --header "Content-Type: application/vnd.api+json" --request POST --data '{"data": {"type": "authentication-tokens","attributes": {"description":"api"}}}' https://${dns_hostname}.${dns_zonename}/$AGENT_POOL | jq '.data.attributes.token' | tr -d '"'`
      echo Use this in your Terraform variables as a value for AGENT_TOKEN=$AGENT_TOKEN
    permissions: '0777'
    path: /tmp/tfe_setup.sh 
  - content: |
      #!/usr/bin/env bash
      # Download all the software and files needed
      apt-get -y install awscli
      aws s3 cp s3://${tag_prefix}-software/${filename_airgap} /tmp/${filename_airgap}
      aws s3 cp s3://${tag_prefix}-software/${filename_license} /tmp/${filename_license}
      aws s3 cp s3://${tag_prefix}-software/${filename_bootstrap} /tmp/${filename_bootstrap}
      aws s3 cp s3://${tag_prefix}-software/certificate_pem /tmp/certificate_pem
      aws s3 cp s3://${tag_prefix}-software/issuer_pem /tmp/issuer_pem
      aws s3 cp s3://${tag_prefix}-software/private_key_pem /tmp/private_key_pem
      
      # Create a full chain from the certificates
      cat /tmp/certificate_pem >> /tmp/fullchain_pem
      cat /tmp/issuer_pem >> /tmp/fullchain_pem
      
      # directory for decompress the file
      sudo mkdir -p /opt/tfe
      pushd /opt/tfe
      sudo tar xzf /tmp/replicated.tar.gz
    permissions: '0750'
    path: /tmp/download_and_unpack_software.sh 
  - content: |
      #!/usr/bin/env bash
      pushd /opt/tfe
      sudo bash ./install.sh airgap private-address=${tfe-private-ip}
    permissions: '0750'
    path: /tmp/install_tfe.sh   
runcmd:
  - sudo bash /tmp/install_software.sh 
  - sudo bash /tmp/download_and_unpack_software.sh 
  - sudo bash /tmp/install_tfe.sh 
packages_update: true  
